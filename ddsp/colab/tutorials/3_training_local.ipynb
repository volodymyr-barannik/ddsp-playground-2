{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpJd3dlOCStH"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/magenta/ddsp/blob/main/ddsp/colab/tutorials/3_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMqWDc_m6rUC"
   },
   "source": [
    "\n",
    "##### Copyright 2021 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNhgka4UKNjf"
   },
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFIqwYGbZ-df"
   },
   "source": [
    "# DDSP Training\n",
    "\n",
    "This notebook demonstrates the libraries in [https://github.com/magenta/ddsp/tree/master/ddsp/training](https://github.com/magenta/ddsp/tree/master/ddsp/training). It is a simple example, overfitting a single audio sample, for educational purposes. \n",
    "\n",
    "_For a full training pipeline please use [ddsp/training/ddsp_run.py](https://github.com/magenta/ddsp/blob/main/ddsp/training/README.md#train-1) as in the [train_autoencoder.ipynb](https://github.com/magenta/ddsp/blob/main/ddsp/colab/demos/train_autoencoder.ipynb)_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "id": "S_jXCnwZ2QYW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (e:\\code\\software\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached tensorflow-2.8.0-cp310-cp310-win_amd64.whl (438.0 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.24.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.22.2-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp310-cp310-win_amd64.whl (3.4 MB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.13.3-cp310-cp310-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vovab\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Using cached protobuf-3.19.4-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vovab\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (60.9.3)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.0-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tf-estimator-nightly, termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, certifi, wrapt, wheel, werkzeug, urllib3, typing-extensions, tensorflow-io-gcs-filesystem, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, numpy, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, cachetools, absl-py, requests, opt-einsum, keras-preprocessing, h5py, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 certifi-2021.10.8 charset-normalizer-2.0.12 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 idna-3.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 numpy-1.22.2 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.1.1 urllib3-1.26.8 werkzeug-2.0.3 wheel-0.37.1 wrapt-1.13.3\n"
     ]
    }
   ],
   "source": [
    "# Install and import dependencies\n",
    "#%tensorflow_version 2.x\n",
    "!pip install tensorflow\n",
    "!pip install -qU ddsp\n",
    "\n",
    "# Ignore a bunch of deprecation warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import ddsp\n",
    "from ddsp.training import (data, decoders, encoders, models, preprocessing, \n",
    "                           train_util, trainers)\n",
    "DEFAULT_SAMPLE_RATE = 16000\n",
    "\n",
    "DEFAULT_SAMPLE_RATE = ddsp.spectral_ops.CREPE_SAMPLE_RATE\n",
    "\n",
    "_play_count = 0  # Used for ephemeral play().\n",
    "\n",
    "# Alias these for backwards compatibility and ease.\n",
    "specplot = ddsp.training.plotting.specplot\n",
    "plot_impulse_responses = ddsp.training.plotting.plot_impulse_responses\n",
    "transfer_function = ddsp.training.plotting.transfer_function\n",
    "\n",
    "\n",
    "def play(array_of_floats,\n",
    "         sample_rate=DEFAULT_SAMPLE_RATE,\n",
    "         ephemeral=True,\n",
    "         autoplay=False):\n",
    "  \"\"\"Creates an HTML5 audio widget to play a sound in Colab.\n",
    "\n",
    "  This function should only be called from a Colab notebook.\n",
    "\n",
    "  Args:\n",
    "    array_of_floats: A 1D or 2D array-like container of float sound samples.\n",
    "      Values outside of the range [-1, 1] will be clipped.\n",
    "    sample_rate: Sample rate in samples per second.\n",
    "    ephemeral: If set to True, the widget will be ephemeral, and disappear on\n",
    "      reload (and it won't be counted against realtime document size).\n",
    "    autoplay: If True, automatically start playing the sound when the widget is\n",
    "      rendered.\n",
    "  \"\"\"\n",
    "  # If batched, take first element.\n",
    "  if len(array_of_floats.shape) == 2:\n",
    "    array_of_floats = array_of_floats[0]\n",
    "\n",
    "  normalizer = float(np.iinfo(np.int16).max)\n",
    "  array_of_ints = np.array(\n",
    "      np.asarray(array_of_floats) * normalizer, dtype=np.int16)\n",
    "  memfile = open(\"res.wav\", \"wb\")\n",
    "  wavfile.write(memfile, sample_rate, array_of_ints)\n",
    "  memfile.close()\n",
    "\n",
    "  global _play_count\n",
    "  _play_count += 1\n",
    "\n",
    "import gin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "sample_rate = DEFAULT_SAMPLE_RATE  # 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khYj8yiMDxGL"
   },
   "source": [
    "# Get a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IzzaWKxVkYms"
   },
   "outputs": [],
   "source": [
    "# Get a single example from NSynth.\n",
    "# Takes a few seconds to load from GCS.\n",
    "data_provider = data.NSynthTfds(split='test')\n",
    "dataset = data_provider.get_batch(batch_size=1, shuffle=False).take(1).repeat()\n",
    "batch = next(iter(dataset))\n",
    "audio = batch['audio']\n",
    "n_samples = audio.shape[1]\n",
    "\n",
    "specplot(audio)\n",
    "play(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acGO0ifg0I3k"
   },
   "source": [
    "# Get a distribution strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUlAeW40Wsvr"
   },
   "outputs": [],
   "source": [
    "strategy = train_util.get_strategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Op0V8onI0VUK"
   },
   "source": [
    "# Get model and trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWZQXFLehCU0"
   },
   "source": [
    "## python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCqXRY1KeX8S"
   },
   "outputs": [],
   "source": [
    "TIME_STEPS = 1000\n",
    "\n",
    "# Create Neural Networks.\n",
    "preprocessor = preprocessing.F0LoudnessPreprocessor(time_steps=TIME_STEPS)\n",
    "\n",
    "decoder = decoders.RnnFcDecoder(rnn_channels = 256,\n",
    "                                rnn_type = 'gru',\n",
    "                                ch = 256,\n",
    "                                num_layers = 1,\n",
    "                                input_keys = ('ld_scaled', 'f0_scaled'),\n",
    "                                output_splits = (('amps', 1),\n",
    "                                                 ('harmonic_distribution', 45),\n",
    "                                                 ('noise_magnitudes', 45)))\n",
    "\n",
    "# Create Processors.\n",
    "harmonic = ddsp.synths.Harmonic(n_samples=n_samples, \n",
    "                                sample_rate=sample_rate,\n",
    "                                name='harmonic')\n",
    "\n",
    "noise = ddsp.synths.FilteredNoise(window_size=0,\n",
    "                                  initial_bias=-10.0,\n",
    "                                  name='noise')\n",
    "add = ddsp.processors.Add(name='add')\n",
    "\n",
    "# Create ProcessorGroup.\n",
    "dag = [(harmonic, ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "       (noise, ['noise_magnitudes']),\n",
    "       (add, ['noise/signal', 'harmonic/signal'])]\n",
    "\n",
    "processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
    "                                                 name='processor_group')\n",
    "\n",
    "\n",
    "# Loss_functions\n",
    "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                         mag_weight=1.0,\n",
    "                                         logmag_weight=1.0)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Put it together in a model.\n",
    "  model = models.Autoencoder(preprocessor=preprocessor,\n",
    "                             encoder=None,\n",
    "                             decoder=decoder,\n",
    "                             processor_group=processor_group,\n",
    "                             losses=[spectral_loss])\n",
    "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAZgDMV9hGyp"
   },
   "source": [
    "## or [`gin`](https://github.com/google/gin-config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JPmTwQshVya"
   },
   "outputs": [],
   "source": [
    "gin_string = \"\"\"\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "\n",
    "# Preprocessor\n",
    "models.Autoencoder.preprocessor = @preprocessing.F0LoudnessPreprocessor()\n",
    "preprocessing.F0LoudnessPreprocessor.time_steps = 1000\n",
    "\n",
    "\n",
    "# Encoder\n",
    "models.Autoencoder.encoder = None\n",
    "\n",
    "# Decoder\n",
    "models.Autoencoder.decoder = @decoders.RnnFcDecoder()\n",
    "decoders.RnnFcDecoder.rnn_channels = 256\n",
    "decoders.RnnFcDecoder.rnn_type = 'gru'\n",
    "decoders.RnnFcDecoder.ch = 256\n",
    "decoders.RnnFcDecoder.num_layers = 1\n",
    "decoders.RnnFcDecoder.input_keys = ('ld_scaled', 'f0_scaled')\n",
    "decoders.RnnFcDecoder.output_splits = (('amps', 1),\n",
    "                                       ('harmonic_distribution', 20),\n",
    "                                       ('noise_magnitudes', 20))\n",
    "\n",
    "# ProcessorGroup\n",
    "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
    "\n",
    "processors.ProcessorGroup.dag = [\n",
    "  (@harmonic/synths.Harmonic(),\n",
    "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "  (@noise/synths.FilteredNoise(),\n",
    "    ['noise_magnitudes']),\n",
    "  (@add/processors.Add(),\n",
    "    ['noise/signal', 'harmonic/signal']),\n",
    "]\n",
    "\n",
    "# Harmonic Synthesizer\n",
    "harmonic/synths.Harmonic.name = 'harmonic'\n",
    "harmonic/synths.Harmonic.n_samples = 64000\n",
    "harmonic/synths.Harmonic.scale_fn = @core.exp_sigmoid\n",
    "\n",
    "# Filtered Noise Synthesizer\n",
    "noise/synths.FilteredNoise.name = 'noise'\n",
    "noise/synths.FilteredNoise.n_samples = 64000\n",
    "noise/synths.FilteredNoise.window_size = 0\n",
    "noise/synths.FilteredNoise.scale_fn = @core.exp_sigmoid\n",
    "noise/synths.FilteredNoise.initial_bias = -10.0\n",
    "\n",
    "# Add\n",
    "add/processors.Add.name = 'add'\n",
    "\n",
    "models.Autoencoder.losses = [\n",
    "    @losses.SpectralLoss(),\n",
    "]\n",
    "losses.SpectralLoss.loss_type = 'L1'\n",
    "losses.SpectralLoss.mag_weight = 1.0\n",
    "losses.SpectralLoss.logmag_weight = 1.0\n",
    "\"\"\"\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_string)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Autoencoder arguments are filled by gin.\n",
    "  model = ddsp.training.models.Autoencoder()\n",
    "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnnxpYbRrPrp"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGvCE5BbrWTU"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lQW604_QWm1"
   },
   "outputs": [],
   "source": [
    "# Build model, easiest to just run forward pass.\n",
    "dataset = trainer.distribute_dataset(dataset)\n",
    "trainer.build(next(iter(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFEqt6e1DsqG"
   },
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LWdoRIONDxri"
   },
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)\n",
    "\n",
    "for i in range(300):\n",
    "  losses = trainer.train_step(dataset_iter)\n",
    "  res_str = 'step: {}\\t'.format(i)\n",
    "  for k, v in losses.items():\n",
    "    res_str += '{}: {:.2f}\\t'.format(k, v)\n",
    "  print(res_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cj220vSF8_Y"
   },
   "source": [
    "# Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDU_FysURm_Z"
   },
   "outputs": [],
   "source": [
    "# Run a batch of predictions.\n",
    "start_time = time.time()\n",
    "controls =  model(next(dataset_iter))\n",
    "audio_gen = model.get_audio_from_outputs(controls)\n",
    "print('Prediction took %.1f seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AlE5kkroHiFr"
   },
   "outputs": [],
   "source": [
    "print('Original Audio')\n",
    "play(audio)\n",
    "print('Resynthesized Audio')\n",
    "play(audio_gen)\n",
    "print('Filtered Noise Audio')\n",
    "audio_noise = controls['noise']['signal']\n",
    "play(audio_noise)\n",
    "\n",
    "specplot(audio)\n",
    "specplot(audio_gen)\n",
    "specplot(audio_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVhoLzV-ZYav"
   },
   "outputs": [],
   "source": [
    "batch_idx = 0\n",
    "get = lambda key: ddsp.core.nested_lookup(key, controls)[batch_idx]\n",
    "\n",
    "amps = get('harmonic/controls/amplitudes')\n",
    "harmonic_distribution = get('harmonic/controls/harmonic_distribution')\n",
    "noise_magnitudes = get('noise/controls/magnitudes')\n",
    "f0_hz = get('f0_hz')\n",
    "loudness = get('loudness_db')\n",
    "\n",
    "audio_noise = get('noise/signal')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "f.suptitle('Input Features', fontsize=16)\n",
    "ax[0].plot(loudness)\n",
    "ax[0].set_ylabel('Loudness')\n",
    "ax[1].plot(f0_hz)\n",
    "ax[1].set_ylabel('F0_Hz')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(14, 4))\n",
    "f.suptitle('Synth Params', fontsize=16)\n",
    "ax[0].semilogy(amps)\n",
    "ax[0].set_ylabel('Amps')\n",
    "ax[0].set_ylim(1e-5, 2)\n",
    "# ax[0].semilogy(harmonic_distribution)\n",
    "ax[1].matshow(np.rot90(np.log10(harmonic_distribution + 1e-6)),\n",
    "              cmap=plt.cm.magma, \n",
    "              aspect='auto')\n",
    "ax[1].set_ylabel('Harmonic Distribution')\n",
    "ax[1].set_xticks([])\n",
    "_ = ax[1].set_yticks([])\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(7, 4))\n",
    "# f.suptitle('Filtered Noise Params', fontsize=16)\n",
    "ax.matshow(np.rot90(np.log10(noise_magnitudes + 1e-6)), \n",
    "           cmap=plt.cm.magma, \n",
    "           aspect='auto')\n",
    "ax.set_ylabel('Filtered Noise Magnitudes')\n",
    "ax.set_xticks([])\n",
    "_ = ax.set_yticks([])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "hMqWDc_m6rUC",
    "ZFIqwYGbZ-df",
    "khYj8yiMDxGL",
    "acGO0ifg0I3k",
    "Op0V8onI0VUK",
    "EWZQXFLehCU0",
    "uAZgDMV9hGyp",
    "MnnxpYbRrPrp",
    "IGvCE5BbrWTU",
    "RFEqt6e1DsqG",
    "2cj220vSF8_Y"
   ],
   "last_runtime": {},
   "name": "3_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}